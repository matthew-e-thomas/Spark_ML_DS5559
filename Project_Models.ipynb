{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matt Thomas, Max McGaw, Liam Mulcahy, Will Carruthers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline  \n",
    "from pyspark.ml.feature import *  \n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('train_data.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+---------+----------+--------+--------------+-----------+-----------+----------+----------+--------------+---------------+--------+---------+--------------+\n",
      "|_c0|loan_status_binary|loan_amnt|      term|int_rate|home_ownership|tot_cur_bal|total_pymnt|annual_inc|addr_state|fico_range_low|last_pymnt_amnt|grade_CD|grade_EFG|emp_length_low|\n",
      "+---+------------------+---------+----------+--------+--------------+-----------+-----------+----------+----------+--------------+---------------+--------+---------+--------------+\n",
      "|  0|                 0|  11000.0| 36 months|    7.21|           ANY|    28511.0|    1354.03|   40000.0|        PA|         715.0|         340.71|       0|        0|             0|\n",
      "|  1|                 0|   4000.0| 36 months|    22.9|           ANY|   108997.0|    1386.67|   40000.0|        MI|         665.0|         154.64|       0|        1|             0|\n",
      "+---+------------------+---------+----------+--------+--------------+-----------+-----------+----------+----------+--------------+---------------+--------+---------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = df.select([col for col in df.columns if col not in ['addr_state','_c0', 'emp_length','emp_length_low']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+----------+--------+--------------+-----------+-----------+----------+--------------+---------------+--------+---------+\n",
      "|loan_status_binary|loan_amnt|      term|int_rate|home_ownership|tot_cur_bal|total_pymnt|annual_inc|fico_range_low|last_pymnt_amnt|grade_CD|grade_EFG|\n",
      "+------------------+---------+----------+--------+--------------+-----------+-----------+----------+--------------+---------------+--------+---------+\n",
      "|                 0|  11000.0| 36 months|    7.21|           ANY|    28511.0|    1354.03|   40000.0|         715.0|         340.71|       0|        0|\n",
      "|                 0|   4000.0| 36 months|    22.9|           ANY|   108997.0|    1386.67|   40000.0|         665.0|         154.64|       0|        1|\n",
      "|                 0|  10000.0| 36 months|   17.97|           ANY|    20320.0|    1435.54|   60000.0|         665.0|         361.38|       1|        0|\n",
      "|                 0|  13000.0| 36 months|   10.91|           ANY|    34947.0|  14686.205|   45000.0|         725.0|        7470.61|       0|        0|\n",
      "|                 0|   7400.0| 36 months|   12.62|           ANY|   253930.0|    3481.88|   51435.0|         705.0|         247.99|       1|        0|\n",
      "+------------------+---------+----------+--------+--------------+-----------+-----------+----------+--------------+---------------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_status_binary: integer (nullable = true)\n",
      " |-- loan_amnt: double (nullable = true)\n",
      " |-- term: string (nullable = true)\n",
      " |-- int_rate: double (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- tot_cur_bal: double (nullable = true)\n",
      " |-- total_pymnt: double (nullable = true)\n",
      " |-- annual_inc: double (nullable = true)\n",
      " |-- fico_range_low: double (nullable = true)\n",
      " |-- last_pymnt_amnt: double (nullable = true)\n",
      " |-- grade_CD: integer (nullable = true)\n",
      " |-- grade_EFG: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70018"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.filter(dfs['tot_cur_bal'].isNull()).count()\n",
    "#Need to do something abou this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = dfs.randomSplit([0.8, 0.2], seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['home_ownership', 'term']\n",
    "stages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categories:\n",
    "    stringIndexer = StringIndexer(inputCol=col, outputCol=col + \"_Index\")\n",
    "    encoder = OneHotEncoder(inputCol=stringIndexer.getOutputCol(),\n",
    "                            outputCol=col + \"classVec\")\n",
    "    stages += [stringIndexer, encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AT added\n",
    "#va = VectorAssembler(inputCols=[\"home_ownershipclassVec\", \"termclassVec\"], outputCol=\"features\")  \n",
    "#stages += [va]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_vectors = VectorAssembler(inputCols = ['loan_amnt',\\\n",
    "                                             'total_pymnt', 'annual_inc', \\\n",
    "                                             'fico_range_low', 'last_pymnt_amnt',\\\n",
    "                                             'int_rate'], outputCol='vector_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AT commented\n",
    "#output = scaled_vectors.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol='vector_features', outputCol='scaled_features')\n",
    "#scaler = StandardScaler(inputCol='vector_features', outputCol='scaled_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelIndexer = StringIndexer(inputCol='loan_status_binary', outputCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AT added\n",
    "assembler = VectorAssembler(inputCols=['scaled_features', 'home_ownershipclassVec', 'termclassVec', 'grade_EFG', 'grade_CD' ], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages += [scaled_vectors, scaler, labelIndexer, assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AT commented\n",
    "#assembler = VectorAssembler(inputCols=['scaled_features', 'home_ownershipclassVec',\\\n",
    "#                                       'grade_CD', 'termclassVec',\\\n",
    "#                                       'grade_EFG'], outputCol='features')\n",
    "#stages += [scaler, labelIndexer, assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_04a394ff8bbb,\n",
       " OneHotEncoder_1ee409dcfcf9,\n",
       " StringIndexer_dd11e97877e6,\n",
       " OneHotEncoder_443f25da0d34,\n",
       " VectorAssembler_2b81480e6240,\n",
       " StandardScaler_eb5892137e04,\n",
       " StringIndexer_64a9c83f9577,\n",
       " VectorAssembler_4421b4096779,\n",
       " LogisticRegression_96a3061e05a7]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(maxIter=10, regParam=0.01)\n",
    "stages += [lr]\n",
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline\n",
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+----------+--------+--------------+-----------+-----------+----------+--------------+---------------+--------+---------+--------------------+----------------------+----------+-------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+----------+\n",
      "|loan_status_binary|loan_amnt|      term|int_rate|home_ownership|tot_cur_bal|total_pymnt|annual_inc|fico_range_low|last_pymnt_amnt|grade_CD|grade_EFG|home_ownership_Index|home_ownershipclassVec|term_Index| termclassVec|     vector_features|     scaled_features|label|            features|       rawPrediction|         probability|prediction|\n",
      "+------------------+---------+----------+--------+--------------+-----------+-----------+----------+--------------+---------------+--------+---------+--------------------+----------------------+----------+-------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+----------+\n",
      "|                 0|    500.0| 36 months|    9.76|      MORTGAGE|       null|   578.7681|   59000.0|         740.0|          17.25|       0|        0|                 0.0|         (5,[0],[1.0])|       0.0|(1,[0],[1.0])|[500.0,578.7681,5...|[0.05441014388227...|  0.0|(14,[0,1,2,3,4,5,...|[2.52084704895599...|[0.92559041450146...|       0.0|\n",
      "|                 0|    600.0| 36 months|   17.66|         OTHER|       null|     445.56|   23826.0|         640.0|          21.59|       0|        1|                 4.0|         (5,[4],[1.0])|       0.0|(1,[0],[1.0])|[600.0,445.56,238...|[0.06529217265872...|  0.0|[0.06529217265872...|[0.64390294882792...|[0.65563519384036...|       0.0|\n",
      "+------------------+---------+----------+--------+--------------+-----------+-----------+----------+--------------+---------------+--------+---------+--------------------+----------------------+----------+-------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction\n",
    "prediction = model.transform(test)\n",
    "prediction.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = prediction.withColumn(\"loan_status_binary\", df[\"loan_status_binary\"].cast('float'))\n",
    "#This is necessary to compare predictions with actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = prediction.filter(prediction['loan_status_binary'] == prediction['prediction']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = prediction.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8812233175845823\n"
     ]
    }
   ],
   "source": [
    "accuracy = matches / counts\n",
    "print(f\"accuracy = {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook ../Spark_ML_DS5559/Final_Project_DS5559_data.ipynb to pdf\n",
      "[NbConvertApp] Support files will be in Final_Project_DS5559_data_files/\n",
      "[NbConvertApp] Making directory ./Final_Project_DS5559_data_files\n",
      "[NbConvertApp] Writing 80572 bytes to ./notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 96996 bytes to ../Spark_ML_DS5559/Final_Project_DS5559_data.pdf\n",
      "[NbConvertApp] Converting notebook ../Spark_ML_DS5559/Project_Models.ipynb to pdf\n",
      "[NbConvertApp] Writing 43276 bytes to ./notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 43651 bytes to ../Spark_ML_DS5559/Project_Models.pdf\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to pdf '../Spark_ML_DS5559'/*.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5559",
   "language": "python",
   "name": "ds5559"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
