{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matt Thomas, Max McGaw, Liam Mulcahy, Will Carruthers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline  \n",
    "from pyspark.ml.feature import *  \n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('train_data.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+---------+----------+--------+--------------+-----------+-----------+----------+----------+--------------+---------------+--------+---------+--------------+\n",
      "|_c0|loan_status_binary|loan_amnt|      term|int_rate|home_ownership|tot_cur_bal|total_pymnt|annual_inc|addr_state|fico_range_low|last_pymnt_amnt|grade_CD|grade_EFG|emp_length_low|\n",
      "+---+------------------+---------+----------+--------+--------------+-----------+-----------+----------+----------+--------------+---------------+--------+---------+--------------+\n",
      "|  0|                 0|  11000.0| 36 months|    7.21|           ANY|    28511.0|    1354.03|   40000.0|        PA|         715.0|         340.71|       0|        0|             0|\n",
      "|  1|                 0|   4000.0| 36 months|    22.9|           ANY|   108997.0|    1386.67|   40000.0|        MI|         665.0|         154.64|       0|        1|             0|\n",
      "+---+------------------+---------+----------+--------+--------------+-----------+-----------+----------+----------+--------------+---------------+--------+---------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = df.select([col for col in df.columns if col not in ['_c0']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+----------+--------+--------------+-----------+-----------+----------+----------+--------------+---------------+--------+---------+--------------+\n",
      "|loan_status_binary|loan_amnt|      term|int_rate|home_ownership|tot_cur_bal|total_pymnt|annual_inc|addr_state|fico_range_low|last_pymnt_amnt|grade_CD|grade_EFG|emp_length_low|\n",
      "+------------------+---------+----------+--------+--------------+-----------+-----------+----------+----------+--------------+---------------+--------+---------+--------------+\n",
      "|                 0|  11000.0| 36 months|    7.21|           ANY|    28511.0|    1354.03|   40000.0|        PA|         715.0|         340.71|       0|        0|             0|\n",
      "|                 0|   4000.0| 36 months|    22.9|           ANY|   108997.0|    1386.67|   40000.0|        MI|         665.0|         154.64|       0|        1|             0|\n",
      "|                 0|  10000.0| 36 months|   17.97|           ANY|    20320.0|    1435.54|   60000.0|        CA|         665.0|         361.38|       1|        0|             1|\n",
      "|                 0|  13000.0| 36 months|   10.91|           ANY|    34947.0|  14686.205|   45000.0|        NH|         725.0|        7470.61|       0|        0|             1|\n",
      "|                 0|   7400.0| 36 months|   12.62|           ANY|   253930.0|    3481.88|   51435.0|        AZ|         705.0|         247.99|       1|        0|             0|\n",
      "+------------------+---------+----------+--------+--------------+-----------+-----------+----------+----------+--------------+---------------+--------+---------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- loan_status_binary: integer (nullable = true)\n",
      " |-- loan_amnt: double (nullable = true)\n",
      " |-- term: string (nullable = true)\n",
      " |-- int_rate: double (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- tot_cur_bal: double (nullable = true)\n",
      " |-- total_pymnt: double (nullable = true)\n",
      " |-- annual_inc: double (nullable = true)\n",
      " |-- addr_state: string (nullable = true)\n",
      " |-- fico_range_low: double (nullable = true)\n",
      " |-- last_pymnt_amnt: double (nullable = true)\n",
      " |-- grade_CD: integer (nullable = true)\n",
      " |-- grade_EFG: integer (nullable = true)\n",
      " |-- emp_length_low: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70018"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.filter(dfs['tot_cur_bal'].isNull()).count()\n",
    "#Need to do something abou this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = dfs.randomSplit([0.8, 0.2], seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['home_ownership', 'term']\n",
    "stages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categories:\n",
    "    stringIndexer = StringIndexer(inputCol=col, outputCol=col + \"_Index\")\n",
    "    encoder = OneHotEncoder(inputCol=stringIndexer.getOutputCol(),\n",
    "                            outputCol=col + \"classVec\")\n",
    "    stages += [stringIndexer, encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_vectors = VectorAssembler(inputCols = ['loan_amnt',\\\n",
    "                                             'total_pymnt', 'annual_inc', \\\n",
    "                                             'fico_range_low', 'last_pymnt_amnt',\\\n",
    "                                             'int_rate','emp_length_low'], \n",
    "                                 outputCol='vector_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol='vector_features', outputCol='scaled_features')\n",
    "#scaler = StandardScaler(inputCol='vector_features', outputCol='scaled_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelIndexer = StringIndexer(inputCol='loan_status_binary', outputCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AT added\n",
    "assembler = VectorAssembler(inputCols=['scaled_features', 'home_ownershipclassVec', 'termclassVec', 'grade_EFG', 'grade_CD' ], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages += [scaled_vectors, scaler, labelIndexer, assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AT commented\n",
    "#assembler = VectorAssembler(inputCols=['scaled_features', 'home_ownershipclassVec',\\\n",
    "#                                       'grade_CD', 'termclassVec',\\\n",
    "#                                       'grade_EFG'], outputCol='features')\n",
    "#stages += [scaler, labelIndexer, assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_18a6eeab5f6e,\n",
       " OneHotEncoder_90fe2cd0f362,\n",
       " StringIndexer_f2279e872e20,\n",
       " OneHotEncoder_b288e2cb0f26,\n",
       " VectorAssembler_1697fcb40d2e,\n",
       " StandardScaler_a0b253e1c1bb,\n",
       " StringIndexer_21b8798202b0,\n",
       " VectorAssembler_cf9b434c62ea,\n",
       " LogisticRegression_4f9a800c1d80]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(maxIter=10, regParam=0.01)\n",
    "stages += [lr]\n",
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline\n",
    "model = crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+----------+--------+--------------+-----------+-----------+----------+----------+--------------+---------------+--------+---------+--------------+--------------------+----------------------+----------+-------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+----------+\n",
      "|loan_status_binary|loan_amnt|      term|int_rate|home_ownership|tot_cur_bal|total_pymnt|annual_inc|addr_state|fico_range_low|last_pymnt_amnt|grade_CD|grade_EFG|emp_length_low|home_ownership_Index|home_ownershipclassVec|term_Index| termclassVec|     vector_features|     scaled_features|label|            features|       rawPrediction|         probability|prediction|\n",
      "+------------------+---------+----------+--------+--------------+-----------+-----------+----------+----------+--------------+---------------+--------+---------+--------------+--------------------+----------------------+----------+-------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+----------+\n",
      "|                 0|    500.0| 36 months|    9.76|      MORTGAGE|       null|   578.7681|   59000.0|        NY|         740.0|          17.25|       0|        0|             0|                 0.0|         (5,[0],[1.0])|       0.0|(1,[0],[1.0])|[500.0,578.7681,5...|[0.05441014388227...|  0.0|(15,[0,1,2,3,4,5,...|[2.48808971096664...|[0.92330263510290...|       0.0|\n",
      "|                 0|    600.0| 36 months|   17.66|         OTHER|       null|     445.56|   23826.0|        WA|         640.0|          21.59|       0|        1|             0|                 4.0|         (5,[4],[1.0])|       0.0|(1,[0],[1.0])|[600.0,445.56,238...|[0.06529217265872...|  0.0|[0.06529217265872...|[0.59893484615134...|[0.64541257802105...|       0.0|\n",
      "+------------------+---------+----------+--------+--------------+-----------+-----------+----------+----------+--------------+---------------+--------+---------+--------------+--------------------+----------------------+----------+-------------+--------------------+--------------------+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction\n",
    "prediction = model.transform(test)\n",
    "prediction.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = prediction.withColumn(\"loan_status_binary\", df[\"loan_status_binary\"].cast('float'))\n",
    "#This is necessary to compare predictions with actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = prediction.filter(prediction['loan_status_binary'] == prediction['prediction']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = prediction.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8811348828571491\n"
     ]
    }
   ],
   "source": [
    "accuracy = matches / counts\n",
    "print(f\"accuracy = {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook ../Spark_ML_DS5559/Final_Project_DS5559_data.ipynb to pdf\n",
      "[NbConvertApp] Support files will be in Final_Project_DS5559_data_files/\n",
      "[NbConvertApp] Making directory ./Final_Project_DS5559_data_files\n",
      "[NbConvertApp] Writing 80572 bytes to ./notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 96996 bytes to ../Spark_ML_DS5559/Final_Project_DS5559_data.pdf\n",
      "[NbConvertApp] Converting notebook ../Spark_ML_DS5559/Project_Models.ipynb to pdf\n",
      "[NbConvertApp] Writing 43276 bytes to ./notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 43651 bytes to ../Spark_ML_DS5559/Project_Models.pdf\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to pdf '../Spark_ML_DS5559'/*.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5559",
   "language": "python",
   "name": "ds5559"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
